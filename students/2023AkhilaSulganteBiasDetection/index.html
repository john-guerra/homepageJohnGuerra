<!doctype html>

<html lang="en">
  <head>
    <meta charset="utf-8" />

    <title>
      State of the art for fairness detection in Machine Learning dataset
    </title>
    <meta
      name="description"
      content="Benchmark Study of Arquero, DuckDB-WASM, and VanillaJS"
    />
    <meta name="author" content="Akhila Sulgante" />

    <link rel="stylesheet" href="css/styles.css?v=1.0" />
    <!-- Latest compiled and minified CSS -->
    <link
      rel="stylesheet"
      href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css"
    />
    <!-- jQuery library -->
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
    <!-- Latest compiled JavaScript -->
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js"></script>
  </head>
  <style>
    .thumb {
      margin: 10px;
    }

    .videoDemo {
      margin: 10px;
    }

    body,
    div,
    p {
      text-align: center;
      padding: 10p;
    }
  </style>

  <body>
    <div class="container">
      <div class="row" style="padding: 1%">
        <div class="col-12">
          <h1>
            State of the art for fairness detection in Machine Learning dataset
          </h1>
          <h2>(ClarityLens: A Data Visualization and Machine Learning tool)</h2>
          <p>
            Independent Study project by
            <a href="https://akhilaportfolio.vercel.app/" target="_"
              >Akhila Sulgante</a
            >
            under the supervision of
            <a href="http://johnguerra.co" target="_"
              >John Alexis Guerra GÃ³mez</a
            >
          </p>
          <!-- <img
            width="500"
            src="https://i.postimg.cc/L8sYPTc2/Teaser-Image.png"
          /> -->
          <div
            style="display: flex; justify-content: center; align-items: center"
          >
            <div style="width: 500px; max-width: 100%">
              <div
                style="height: 0; padding-bottom: 48.46%; position: relative"
              >
                <iframe
                  width="500"
                  height="400"
                  style="
                    position: absolute;
                    top: 0;
                    left: 0;
                    width: 100%;
                    height: 100%;
                  "
                  frameborder="0"
                  src="https://imgflip.com/embed/89odlg"
                ></iframe>
              </div>
            </div>
          </div>
        </div>
      </div>
      <div class="row">
        <div class="col-12" style="padding: 1%">
          <a
            class="btn btn-primary"
            role="button"
            href="https://observablehq.com/d/3d39e1f333def77c"
            target="_"
            >Demo</a
          >
          <a
            class="btn btn-primary"
            role="button"
            href="https://www.overleaf.com/read/mhdvcxdkcvhw#6d5ce0"
            target="_"
            >Paper</a
          >
        </div>
      </div>
      <div class="row" style="padding: 1%">
        <div class="col-12"></div>
      </div>
      <div class="row">
        "
        <div class="col-md-2"></div>
        <div class="col-md-8" style="padding: 2%">
          <h2>Objective</h2>
          <p>
            Our primary objective was to empower users to identify and
            understand potential biases within the datasets, fostering
            transparency and accountability in machine learning processes.
            Through innovative visualization techniques, the tool provides a
            dynamic environment for users to navigate through diverse datasets,
            gaining insights into their data, and find co-relation between
            features. The tool will also enable users to understand all aspect
            of training and evaluating a model by authorizing complete control
            to users over the training features, train-train split and
            interpretation of evaluation matrix for bias detection.
          </p>
          <h2>Problem Statement</h2>
          <p>
            Bias in the ML dataset indicates prejudices and unfair inaccuracies
            in the data that is used to train ML models. In simple terms,
            certain groups of a dataset are overweighted or overrepresented.
            This bias can have a significant impact on the fairness of ML
            models. Beyond the technical challenges of ML models producing
            inaccurate results, their implications extend systemically,
            perpetuating discrimination based on age, race, culture, or sexual
            orientation. A real-world case is evident in Amazon's previous
            hiring system, where research identified the discriminatory nature
            of their ML model. This system downgraded resumes containing the
            term "Women," resulting in biased selections that disadvantaged
            female candidates in the top candidate pool.
          </p>
          <h2>Deliverables</h2>
          <ul>
            <li>
              A working demo of the tool
              <a href="https://observablehq.com/d/3d39e1f333def77c"
                >Observable</a
              >
            </li>
            <li>
              A comparsion table representing the state-of-the art of the
              existing tools
            </li>
          </ul>
        </div>
        <div class="col-md-2"></div>
      </div>
    </div>
    <script src="js/scripts.js"></script>
  </body>
</html>
